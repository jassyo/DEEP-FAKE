{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxY8sBCFfs8n"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset (Make sure the path is correct and points to your dataset on Google Drive)\n",
        "dataset = datasets.ImageFolder(root='/content/drive/MyDrive/test2', transform=transform)\n",
        "\n",
        "# Dataset Info\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Class-to-Index Mapping:\", dataset.class_to_idx)\n",
        "print(\"Number of Samples:\", len(dataset))\n",
        "\n",
        "# Initialize the model with dropout\n",
        "def initialize_model_with_dropout(model_name, num_classes=2, dropout_rate=0.5):\n",
        "    if model_name == \"alexnet\":\n",
        "        model = models.alexnet(pretrained=True)\n",
        "        # Freeze convolution layers\n",
        "        for param in model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "        # Replace the final fully connected layers with a Dropout layer and a new classifier\n",
        "        model.classifier[6] = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# Calculate metrics function\n",
        "def calculate_metrics(model, loader, device):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "    TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "    # Accuracy: (TP + TN) / Total\n",
        "    total = conf_matrix.sum()\n",
        "    accuracy = (TP + TN) / total if total > 0 else 0.0\n",
        "\n",
        "    # Precision: TP / (TP + FP)\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "\n",
        "    # Recall: TP / (TP + FN)\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "\n",
        "    # F1-Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return accuracy, precision, recall, f1, conf_matrix\n",
        "\n",
        "# Train the model function with validation accuracy printed after each epoch\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n",
        "    best_val_accuracy = 0\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "        # Track the best model with the highest validation accuracy\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "\n",
        "    return best_val_accuracy\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Cross-validation setup\n",
        "num_folds = 3\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# DataLoader setup\n",
        "batch_size = 32\n",
        "learning_rates = [0.0001, 0.001, 0.01]\n",
        "optimizers_to_test = {'Adam': optim.Adam, 'SGD': optim.SGD}\n",
        "results = {model_name: {opt_name: [] for opt_name in optimizers_to_test} for model_name in [\"alexnet\"]}\n",
        "\n",
        "# Cross-validation loop\n",
        "for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(dataset)):\n",
        "    print(f\"Fold {fold_idx + 1}/{num_folds}\")\n",
        "\n",
        "    # Create training/validation split\n",
        "    train_val_data = torch.utils.data.Subset(dataset, train_val_idx)\n",
        "    test_data = torch.utils.data.Subset(dataset, test_idx)\n",
        "\n",
        "    # Further split training/validation\n",
        "    train_size = int(0.8 * len(train_val_data))\n",
        "    val_size = len(train_val_data) - train_size\n",
        "    train_data, val_data = torch.utils.data.random_split(\n",
        "        train_val_data, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for model_name in [\"alexnet\"]:\n",
        "        best_lr_for_optimizer = {}  # Track the best learning rate for each optimizer\n",
        "\n",
        "        for optimizer_name, optimizer_fn in optimizers_to_test.items():\n",
        "            best_val_accuracy = 0  # Track best validation accuracy for this optimizer\n",
        "            best_lr = None  # Track best learning rate for this optimizer\n",
        "\n",
        "            for lr in learning_rates:\n",
        "                # Initialize the model with dropout\n",
        "                model = initialize_model_with_dropout(model_name, dropout_rate=0.5).to(device)\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "                # Choose optimizer based on the current configuration\n",
        "                if optimizer_name == 'Adam':\n",
        "                    optimizer = optimizer_fn(model.parameters(), lr=lr)\n",
        "                else:\n",
        "                    optimizer = optimizer_fn(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "                # Train the model and get validation accuracy\n",
        "                print(f\"Training {model_name} with {optimizer_name} and LR={lr}\")\n",
        "                _ = train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n",
        "                # Evaluate on Validation set\n",
        "                validation_metrics = calculate_metrics(model, val_loader, device)\n",
        "                val_accuracy = validation_metrics[0]  # Get the validation accuracy\n",
        "\n",
        "                print(f\"Validation Accuracy for {model_name} with {optimizer_name} and LR={lr}: {val_accuracy:.2f}%\")\n",
        "\n",
        "                # Update the best learning rate if needed\n",
        "                if val_accuracy > best_val_accuracy:\n",
        "                    best_val_accuracy = val_accuracy\n",
        "                    best_lr = lr\n",
        "\n",
        "            # After finding the best learning rate, evaluate on the test set\n",
        "            print(f\"Best learning rate for {optimizer_name} is {best_lr} with validation accuracy {best_val_accuracy:.2f}%\")\n",
        "\n",
        "            # Initialize the model with the best learning rate and train again\n",
        "            model = initialize_model_with_dropout(model_name, dropout_rate=0.5).to(device)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            if optimizer_name == 'Adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=best_lr)\n",
        "            else:\n",
        "                optimizer = optim.SGD(model.parameters(), lr=best_lr, momentum=0.9)\n",
        "\n",
        "            # Train the model with the best learning rate\n",
        "            _ = train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n",
        "\n",
        "            # Now evaluate on the test set using the best learning rate\n",
        "            test_metrics = calculate_metrics(model, test_loader, device)\n",
        "            print(f\"Test Metrics for {model_name} with {optimizer_name} and Best LR={best_lr}:\")\n",
        "            print(f\"Accuracy={test_metrics[0]:.2f}, Precision={test_metrics[1]:.2f}, Recall={test_metrics[2]:.2f}, F1-Score={test_metrics[3]:.2f}, Confusion Matrix=\\n{test_metrics[4]}\")\n",
        "\n",
        "            # Store the results for this fold\n",
        "            results[model_name][optimizer_name].append({\n",
        "                'lr': best_lr,\n",
        "                'accuracy': test_metrics[0],\n",
        "                'precision': test_metrics[1],\n",
        "                'recall': test_metrics[2],\n",
        "                'f1': test_metrics[3],\n",
        "                'confusion_matrix': test_metrics[4]\n",
        "            })"
      ]
    }
  ]
}